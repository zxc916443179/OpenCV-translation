# SIFT介绍

## Goal
    在本章节中
        - 我们将学习SIFT算法的基本内容
        - 我们将学习去寻找SIFT关键点和描述符
## Theory
    在过去的章节中，我们了解了几种角点检测算法如哈里斯算法等，它们具有旋转不变性，也就是说，即使将图像旋转，我们依然可以找到同样的角点。显然角点在图像旋转后依然是角点。那么对于缩放呢？一个角点在图片缩放后未必仍是一个角点。举个例子，观察下图。在小图中的一个角点，在图片缩放后是平滑的。因此哈里斯角点算法并不具有尺度不变性。
   ![image](https://opencv-python-tutroals.readthedocs.io/en/latest/_images/sift_scale_invariant.jpg "image")

    因此，在2004年，来自英国哥伦比亚大学的在他的论文《Distinctive Image Features from Scale-Invariant Keypoints》中提出了一种新的算法————尺度不变特征算法，这种算法可以用来提取关键点和计算描述符。（这篇paper易于理解并被认为是SIFT最好的工具书。因此这里仅对论文做简要的介绍）。
    SIFT算法大致包含四个步骤。我们将一个一个介绍它们。
### 尺度空间极值检测
    根据上面的图片，显然，我们不能够用同一个窗口去检测不同尺度的关键点。检测小的角点是OK的，但检测大的角点我们则需要更大的窗口。对此，我们使用尺度空间过滤。其中，有人提出使用高斯拉普拉斯算子应用于含有变量σ值得图像上。LoG 作为一个斑点检测器来检测随着变量σ变化不同的斑点。简单地说，σ就是一个尺度参数。举个例子，在上图中，低σ的高斯内核可以给出小角点更高的值，而高的σ则可以更好地匹配大角点。因此，我们可以得到一个三元组（x,y,σ)的值，它表示在σ的尺度下，点（x，y）是关键点的可能性，我们可以通过这个得到在某个尺度和空间下局部的最大值。
    但是这种LoG效率比较低，因此SIFT算法使用LoG的一种近似————Difference of Gaussian（DoG）。使用两个不同的σ值的图像，分别令它们为σ和kσ，这两个图像的高斯模糊的区别就可以得到高斯差分。这个过程是在高斯金字塔里的不同的八维图像下完成的。如下图所示：
![DoG](https://opencv-python-tutroals.readthedocs.io/en/latest/_images/sift_dog.jpg "DoG")

    一旦这个DoG被建立，就可以从图像中找到尺度和空间上的局部极大值。例如，图像中的一个像素点同时与它周围的八个像素点和下一个尺度的9个像素点、上一个尺度的9个像素点比较，如果它是局部极大值，那么它是一个可能关键点。它基本上就意味着在那个尺度上那个关键点是最好的表示了。如下图所示：
![Scale](https://opencv-python-tutroals.readthedocs.io/en/latest/_images/sift_local_extrema.jpg)

    对于不同的参数，论文给出了一些经验性的值供使用，number of octaves = 4, number of scale levels = 5, 初始化σ = 1.6, k = √2等都是最优值。
---
### 关键点定位
    当可能关键点的位置被找到，它们仍需要再做处理以得到更精确的结果。它们使用尺度空间泰勒展开式来计算极值的精确位置，如果这个极值的密度小于一个门限值（论文中为0.03），它是不可用的。在OpenCV中这个阈值被称为对比阈值。
    DoG对边界的响应程度比较高，因此边界需要被移除。在这点上，它使用的是与哈里斯角点检测相似的思想。它们使用一个2x2的Heissian矩阵来计算主曲率。我们从哈里斯焦点监测器可以知道，对边界而言，一个特征值比另一个大。因此，这里它们用的是用一个方法。
    如果这个比率比阈值大（OpenCV称其为边界阈值），那么关键点将被舍弃。在论文中这个值被设为10。
    因此它可以排除一切的低对比度的关键点和边界关键点，剩下的都是有用的点。
### 方向赋值
    为了实现图像旋转的不变性，我们为每个方向点方向赋值。在不同尺度下于关键点周围选取邻接点，并在那个区域计算梯度和方向导数。这样我们可以得到一个有36个区间涵盖360度的方向直方图。（它由σ值为1.5倍尺度大小的梯度和高斯权重窗口为权值）。我们选取直方图中幅值最高的来计算方向，另外幅值超过80%的也将其纳入考虑范围。它在相同位置和尺度、不同方向下生成特征点。它将有利于匹配的准确度。
### 特征点描述
    现在生成特征点描述符。我们选取特征点周围的16x16的空间并将其分割为16个4x4大小的子块。对于每个子块，可以得到8个区间的方向直方图，故共可得到128个区间的值。它以向量的形式作为特征点的描述符。此外，我们还采取很多方法来应对光照变化、旋转等带来的影响。
### 特征点匹配
    两张图的特征点的匹配可能由于噪声或者其它因素而不尽相同，一般情况下，次最近匹配与最近匹配离的很近。这种情况下，我们去最近距离与次最近距离的比值，如果它大于0.8则舍弃它们。论文中介绍，这样做大约可以排除90%的错误匹配而只舍弃5%的正确匹配。
    至此是SIFT算法的大致介绍。如果想要了解更多细节，强烈推荐阅读原论文。记住一件事，这个算法是有专利权的，因此OpenCV中的这个算法模块并不是免费的。
---
## SIFT in OpenCV
    那么接下来我们看看OpenCV中提供的SIFT函数模块。我们从特征点检测并画出它们开始。首先我们构造一个SIFT对象，其构造函数可以接受多个可选参数，在文档中有各个参数的详细介绍。
```
import cv2
import numpy as np

img = cv2.imread('home.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

sift = cv2.SIFT()
kp = sift.detect(gray, None)

img = cv2.drawKeypoints(gray, kp)
cv2.imwrite('sift_keypoints.jpg', img)
```